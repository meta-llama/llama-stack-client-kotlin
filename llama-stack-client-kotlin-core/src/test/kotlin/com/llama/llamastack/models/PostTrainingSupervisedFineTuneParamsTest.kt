// File generated from our OpenAPI spec by Stainless.

package com.llama.llamastack.models

import com.llama.llamastack.models.*
import org.assertj.core.api.Assertions.assertThat
import org.junit.jupiter.api.Test

class PostTrainingSupervisedFineTuneParamsTest {

    @Test
    fun createPostTrainingSupervisedFineTuneParams() {
        PostTrainingSupervisedFineTuneParams.builder()
            .algorithm(PostTrainingSupervisedFineTuneParams.Algorithm.FULL)
            .algorithmConfig(
                PostTrainingSupervisedFineTuneParams.AlgorithmConfig.ofLoraFinetuningConfig(
                    PostTrainingSupervisedFineTuneParams.AlgorithmConfig.LoraFinetuningConfig
                        .builder()
                        .alpha(0L)
                        .applyLoraToMlp(true)
                        .applyLoraToOutput(true)
                        .loraAttnModules(listOf("string"))
                        .rank(0L)
                        .build()
                )
            )
            .datasetId("dataset_id")
            .hyperparamSearchConfig(
                PostTrainingSupervisedFineTuneParams.HyperparamSearchConfig.builder().build()
            )
            .jobUuid("job_uuid")
            .loggerConfig(PostTrainingSupervisedFineTuneParams.LoggerConfig.builder().build())
            .model("model")
            .optimizerConfig(
                PostTrainingSupervisedFineTuneParams.OptimizerConfig.builder()
                    .lr(0.0)
                    .lrMin(0.0)
                    .optimizerType(
                        PostTrainingSupervisedFineTuneParams.OptimizerConfig.OptimizerType.ADAM
                    )
                    .weightDecay(0.0)
                    .build()
            )
            .trainingConfig(
                PostTrainingSupervisedFineTuneParams.TrainingConfig.builder()
                    .batchSize(0L)
                    .enableActivationCheckpointing(true)
                    .fsdpCpuOffload(true)
                    .memoryEfficientFsdpWrap(true)
                    .nEpochs(0L)
                    .nIters(0L)
                    .shuffle(true)
                    .build()
            )
            .validationDatasetId("validation_dataset_id")
            .xLlamaStackProviderData("X-LlamaStack-ProviderData")
            .build()
    }

    @Test
    fun getBody() {
        val params =
            PostTrainingSupervisedFineTuneParams.builder()
                .algorithm(PostTrainingSupervisedFineTuneParams.Algorithm.FULL)
                .algorithmConfig(
                    PostTrainingSupervisedFineTuneParams.AlgorithmConfig.ofLoraFinetuningConfig(
                        PostTrainingSupervisedFineTuneParams.AlgorithmConfig.LoraFinetuningConfig
                            .builder()
                            .alpha(0L)
                            .applyLoraToMlp(true)
                            .applyLoraToOutput(true)
                            .loraAttnModules(listOf("string"))
                            .rank(0L)
                            .build()
                    )
                )
                .datasetId("dataset_id")
                .hyperparamSearchConfig(
                    PostTrainingSupervisedFineTuneParams.HyperparamSearchConfig.builder().build()
                )
                .jobUuid("job_uuid")
                .loggerConfig(PostTrainingSupervisedFineTuneParams.LoggerConfig.builder().build())
                .model("model")
                .optimizerConfig(
                    PostTrainingSupervisedFineTuneParams.OptimizerConfig.builder()
                        .lr(0.0)
                        .lrMin(0.0)
                        .optimizerType(
                            PostTrainingSupervisedFineTuneParams.OptimizerConfig.OptimizerType.ADAM
                        )
                        .weightDecay(0.0)
                        .build()
                )
                .trainingConfig(
                    PostTrainingSupervisedFineTuneParams.TrainingConfig.builder()
                        .batchSize(0L)
                        .enableActivationCheckpointing(true)
                        .fsdpCpuOffload(true)
                        .memoryEfficientFsdpWrap(true)
                        .nEpochs(0L)
                        .nIters(0L)
                        .shuffle(true)
                        .build()
                )
                .validationDatasetId("validation_dataset_id")
                .xLlamaStackProviderData("X-LlamaStack-ProviderData")
                .build()
        val body = params.getBody()
        assertThat(body).isNotNull
        assertThat(body.algorithm()).isEqualTo(PostTrainingSupervisedFineTuneParams.Algorithm.FULL)
        assertThat(body.algorithmConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.AlgorithmConfig.ofLoraFinetuningConfig(
                    PostTrainingSupervisedFineTuneParams.AlgorithmConfig.LoraFinetuningConfig
                        .builder()
                        .alpha(0L)
                        .applyLoraToMlp(true)
                        .applyLoraToOutput(true)
                        .loraAttnModules(listOf("string"))
                        .rank(0L)
                        .build()
                )
            )
        assertThat(body.datasetId()).isEqualTo("dataset_id")
        assertThat(body.hyperparamSearchConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.HyperparamSearchConfig.builder().build()
            )
        assertThat(body.jobUuid()).isEqualTo("job_uuid")
        assertThat(body.loggerConfig())
            .isEqualTo(PostTrainingSupervisedFineTuneParams.LoggerConfig.builder().build())
        assertThat(body.model()).isEqualTo("model")
        assertThat(body.optimizerConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.OptimizerConfig.builder()
                    .lr(0.0)
                    .lrMin(0.0)
                    .optimizerType(
                        PostTrainingSupervisedFineTuneParams.OptimizerConfig.OptimizerType.ADAM
                    )
                    .weightDecay(0.0)
                    .build()
            )
        assertThat(body.trainingConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.TrainingConfig.builder()
                    .batchSize(0L)
                    .enableActivationCheckpointing(true)
                    .fsdpCpuOffload(true)
                    .memoryEfficientFsdpWrap(true)
                    .nEpochs(0L)
                    .nIters(0L)
                    .shuffle(true)
                    .build()
            )
        assertThat(body.validationDatasetId()).isEqualTo("validation_dataset_id")
    }

    @Test
    fun getBodyWithoutOptionalFields() {
        val params =
            PostTrainingSupervisedFineTuneParams.builder()
                .algorithm(PostTrainingSupervisedFineTuneParams.Algorithm.FULL)
                .algorithmConfig(
                    PostTrainingSupervisedFineTuneParams.AlgorithmConfig.ofLoraFinetuningConfig(
                        PostTrainingSupervisedFineTuneParams.AlgorithmConfig.LoraFinetuningConfig
                            .builder()
                            .alpha(0L)
                            .applyLoraToMlp(true)
                            .applyLoraToOutput(true)
                            .loraAttnModules(listOf("string"))
                            .rank(0L)
                            .build()
                    )
                )
                .datasetId("dataset_id")
                .hyperparamSearchConfig(
                    PostTrainingSupervisedFineTuneParams.HyperparamSearchConfig.builder().build()
                )
                .jobUuid("job_uuid")
                .loggerConfig(PostTrainingSupervisedFineTuneParams.LoggerConfig.builder().build())
                .model("model")
                .optimizerConfig(
                    PostTrainingSupervisedFineTuneParams.OptimizerConfig.builder()
                        .lr(0.0)
                        .lrMin(0.0)
                        .optimizerType(
                            PostTrainingSupervisedFineTuneParams.OptimizerConfig.OptimizerType.ADAM
                        )
                        .weightDecay(0.0)
                        .build()
                )
                .trainingConfig(
                    PostTrainingSupervisedFineTuneParams.TrainingConfig.builder()
                        .batchSize(0L)
                        .enableActivationCheckpointing(true)
                        .fsdpCpuOffload(true)
                        .memoryEfficientFsdpWrap(true)
                        .nEpochs(0L)
                        .nIters(0L)
                        .shuffle(true)
                        .build()
                )
                .validationDatasetId("validation_dataset_id")
                .build()
        val body = params.getBody()
        assertThat(body).isNotNull
        assertThat(body.algorithm()).isEqualTo(PostTrainingSupervisedFineTuneParams.Algorithm.FULL)
        assertThat(body.algorithmConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.AlgorithmConfig.ofLoraFinetuningConfig(
                    PostTrainingSupervisedFineTuneParams.AlgorithmConfig.LoraFinetuningConfig
                        .builder()
                        .alpha(0L)
                        .applyLoraToMlp(true)
                        .applyLoraToOutput(true)
                        .loraAttnModules(listOf("string"))
                        .rank(0L)
                        .build()
                )
            )
        assertThat(body.datasetId()).isEqualTo("dataset_id")
        assertThat(body.hyperparamSearchConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.HyperparamSearchConfig.builder().build()
            )
        assertThat(body.jobUuid()).isEqualTo("job_uuid")
        assertThat(body.loggerConfig())
            .isEqualTo(PostTrainingSupervisedFineTuneParams.LoggerConfig.builder().build())
        assertThat(body.model()).isEqualTo("model")
        assertThat(body.optimizerConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.OptimizerConfig.builder()
                    .lr(0.0)
                    .lrMin(0.0)
                    .optimizerType(
                        PostTrainingSupervisedFineTuneParams.OptimizerConfig.OptimizerType.ADAM
                    )
                    .weightDecay(0.0)
                    .build()
            )
        assertThat(body.trainingConfig())
            .isEqualTo(
                PostTrainingSupervisedFineTuneParams.TrainingConfig.builder()
                    .batchSize(0L)
                    .enableActivationCheckpointing(true)
                    .fsdpCpuOffload(true)
                    .memoryEfficientFsdpWrap(true)
                    .nEpochs(0L)
                    .nIters(0L)
                    .shuffle(true)
                    .build()
            )
        assertThat(body.validationDatasetId()).isEqualTo("validation_dataset_id")
    }
}
